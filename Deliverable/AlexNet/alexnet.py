# -*- coding: utf-8 -*-
"""alexnet_222.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LdNh6YYeTdms4y6bDiLdCy8zUMSP8l9J
"""

# Import libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


import keras
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.preprocessing import image

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn import metrics

from tqdm import tqdm

import tensorflow as tf
from tensorflow import keras

from tqdm import tqdm

import os

from google.colab import drive
drive.mount('/content/gdrive')

"""
# Import images and labels"""

labels = pd.read_csv('/content/gdrive/MyDrive/data_mining/new_labels.csv' )

unique_labels = len(labels.columns)

print(labels['Image Index'])
labels.shape

# show a specific row
labels.loc[labels['Image Index'] == '00000013_015.png']

train_image = []
filepath = '/content/gdrive/MyDrive/data_mining/Selected X_rays'
list_of_images = os.listdir(filepath)[:1000]

image_path = filepath + '/' + labels['Image Index']

for i in tqdm(range(len(list_of_images))):
  img = image.load_img('/content/gdrive/MyDrive/data_mining/Selected X_rays/'+ list_of_images[i], target_size=(400, 400,3))
  img = image.img_to_array(img)
  img = img/255
  train_image.append(img)

images = np.array(train_image)

# Remove labels that are not in list_of_images
labels = labels[labels['Image Index'].isin(list_of_images)]
labels

column_names = labels.drop('Image Index', 1)

column_names = column_names.columns

column_names

print(images.shape, labels.shape)

plt.imshow(images[999], interpolation='nearest')
plt.show()

"""# **Train/test split**"""

labels = np.array(labels.drop(['Image Index'],axis=1))

labels.shape

images.shape

X_train, X_test, y_train, y_test = train_test_split(images, labels, random_state=42, test_size=0.2)

"""# Model architecture

AlexNet
"""

model = keras.models.Sequential([
    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(400, 400,3)),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),
    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),
    keras.layers.Flatten(),
    keras.layers.Dense(4096, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(4096, activation='relu'),
    keras.layers.Dropout(0.5),
    # switched out softmax with sigmoid as it is a multi-label image classification problem
    keras.layers.Dense(15, activation='sigmoid')
])

model.summary()

opt = keras.optimizers.Adam(learning_rate=0.0001)

model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

"""
# Training the model
"""

history = model.fit(X_train, y_train, validation_split=0.33, epochs=30, validation_data=(X_test, y_test), batch_size=32)

model.save('/content/gdrive/MyDrive/data_mining/results/7.h5')

# plot learning curves

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('/content/gdrive/MyDrive/data_mining/results/accuracy_plot_7.png')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('/content/gdrive/MyDrive/data_mining/results/loss_plot_7.png')
plt.show()

model.save('/content/gdrive/MyDrive/data_mining/results/7.h5')

# Plot ROC curve
loaded_model = load_model('/content/gdrive/MyDrive/data_mining/results/4.h5')

Y_pred= loaded_model.predict(X_test, batch_size=10)
y = y_test
y_true = y.ravel()
y_pred = Y_pred.ravel()

false_pos, true_pos, thresh = roc_curve(y_true, y_pred)
"""
plt.figure(figsize = (5,5))
plt.plot([0, 1], [0, 1],  linestyle="--")
plt.plot(false_pos, true_pos)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

y_true_2 = pd.DataFrame(y, columns = column_names)
y_pred_2 = pd.DataFrame(Y_pred, columns = column_names)


for i in column_names:
    print(i)
    false_pos, true_pos, thresh = roc_curve(y_true_2[i], y_pred_2[i])
    globals()["{}". format(i)] = (false_pos, true_pos) 


plt.figure(figsize = (10,10))
plt.plot([0, 1], [0, 1],  linestyle="--")

for i in column_names:
    a = globals()["{}". format(i)]   
    plt.plot(a[0], a[1], label = i)

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(           loc = "lower center", 
           bbox_to_anchor = (0.5, -0.2), 
           ncol=5)
plt.show()"""

auc_score= metrics.auc(false_pos, true_pos)

auc_score